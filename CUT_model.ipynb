{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iuDaCd0OC-7k"
      },
      "source": [
        "# Synthetic-to-Real Chessboard Image Translation (CUT)\n",
        "\n",
        "This notebook implements the **Contrastive Unpaired Translation (CUT)** model to transform synthetic Blender renders into realistic chessboard images.\n",
        "\n",
        "**Main Goal:** Preserve piece positions and geometry while closing the visual domain gap.\n",
        "\n",
        "**Why CUT?** CUT uses contrastive patch-level matching (PatchNCE) so each output patch corresponds to the same input patch. It preserves piece locations better than vanilla CycleGAN while still transferring real-world texture and lighting.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vt0jbNeIC-7l"
      },
      "source": [
        "**Clone the Official CUT Repository**\n",
        "\n",
        "We use the official implementation by Taesung Park for efficiency and stability.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "durydDz2C-7l",
        "outputId": "6291a128-f9c5-4286-e124-7dfe5da1553c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'cycleGAN'...\n",
            "remote: Enumerating objects: 2619, done.\u001b[K\n",
            "remote: Total 2619 (delta 0), reused 0 (delta 0), pack-reused 2619 (from 1)\u001b[K\n",
            "Receiving objects: 100% (2619/2619), 8.23 MiB | 3.46 MiB/s, done.\n",
            "Resolving deltas: 100% (1654/1654), done.\n",
            "/Users/michaln/Documents/Study/×¡×ž×¡×˜×¨ ×”/×œ×ž×™×“×” ×¢×ž×•×§×”/project/Final Project/project_repo/DeepLearning_project3/cycleGAN\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/michaln/.pyenv/versions/3.10.4/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
            "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
          ]
        }
      ],
      "source": [
        "# !git clone https://github.com/taesungp/contrastive-unpaired-translation.git CUT\n",
        "# %cd CUT\n",
        "\n",
        "!git clone https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix.git cycleGAN\n",
        "%cd cycleGAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjR8FIBTC-7m",
        "outputId": "d66e740b-5b3e-486e-9d55-aecff763691c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsGfghEv5zlJ",
        "outputId": "fa92bed8-4b54-48f7-85a8-fc5270bb6b52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting dominate\n",
            "  Downloading dominate-2.9.1-py2.py3-none-any.whl.metadata (13 kB)\n",
            "Downloading dominate-2.9.1-py2.py3-none-any.whl (29 kB)\n",
            "Installing collected packages: dominate\n",
            "Successfully installed dominate-2.9.1\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install dominate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnY0kGoDC-7m"
      },
      "source": [
        "## Prepare the Dataset\n",
        "We will create the directory structure inside the `CUT/datasets` folder and copy your data from Google Drive.\n",
        "\n",
        "**Note:** Ensure your `dataset` folder is uploaded to `My Drive/ChessProject/dataset` (or update the path below).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cut0ho0hC-7m"
      },
      "source": [
        "## Start Training\n",
        "We run the training script.\n",
        "- `--model cut`: Uses the Contrastive Unpaired Translation model.\n",
        "- `--name chess_cut`: The name of the experiment (checkpoints will be saved here).\n",
        "- `--CUT_mode CUT`: Standard CUT mode (you can change to `FastCUT` for faster training).\n",
        "- `--n_epochs` and `--n_epochs_decay`: Control how long to train.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdlCCVAdC-7m",
        "outputId": "815bcf8e-f3a3-4e7d-deaf-bd6bfebe525f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------- Options ---------------\n",
            "               batch_size: 1                             \n",
            "                    beta1: 0.5                           \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "           continue_train: False                         \n",
            "                crop_size: 256                           \n",
            "                 dataroot: ./datasets/chess_data         \t[default: None]\n",
            "             dataset_mode: unaligned                     \n",
            "                direction: AtoB                          \n",
            "             display_freq: 400                           \n",
            "          display_winsize: 256                           \n",
            "                    epoch: latest                        \n",
            "              epoch_count: 1                             \n",
            "                 gan_mode: lsgan                         \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: True                          \t[default: None]\n",
            "                 lambda_A: 10.0                          \n",
            "                 lambda_B: 10.0                          \n",
            "          lambda_identity: 0.5                           \n",
            "                load_iter: 0                             \t[default: 0]\n",
            "                load_size: 286                           \n",
            "                       lr: 0.0002                        \n",
            "           lr_decay_iters: 50                            \n",
            "                lr_policy: linear                        \n",
            "         max_dataset_size: inf                           \n",
            "                    model: cycle_gan                     \n",
            "                 n_epochs: 100                           \n",
            "           n_epochs_decay: 100                           \n",
            "               n_layers_D: 3                             \n",
            "                     name: chess_data_cyclegan           \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                     netD: basic                         \n",
            "                     netG: resnet_9blocks                \n",
            "                      ngf: 64                            \n",
            "               no_dropout: True                          \n",
            "                  no_flip: False                         \n",
            "                  no_html: False                         \n",
            "                     norm: instance                      \n",
            "              num_threads: 4                             \n",
            "                output_nc: 3                             \n",
            "                    phase: train                         \n",
            "                pool_size: 50                            \n",
            "               preprocess: resize_and_crop               \n",
            "               print_freq: 100                           \n",
            "             save_by_iter: False                         \n",
            "          save_epoch_freq: 5                             \n",
            "         save_latest_freq: 5000                          \n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "         update_html_freq: 1000                          \n",
            "                use_wandb: True                          \t[default: False]\n",
            "                  verbose: False                         \n",
            "       wandb_project_name: CycleGAN-and-pix2pix          \n",
            "----------------- End -------------------\n",
            "Initialized with device cuda:0\n",
            "dataset [UnalignedDataset] was created\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "The number of training images = 944\n",
            "model [CycleGANModel] was created\n",
            "Initialized with device cuda:0\n",
            "initialize network with normal\n",
            "Initialized with device cuda:0\n",
            "initialize network with normal\n",
            "Initialized with device cuda:0\n",
            "initialize network with normal\n",
            "Initialized with device cuda:0\n",
            "initialize network with normal\n",
            "---------- Networks initialized -------------\n",
            "[Network G_A] Total number of parameters : 11.378 M\n",
            "[Network G_B] Total number of parameters : 11.378 M\n",
            "[Network D_A] Total number of parameters : 2.765 M\n",
            "[Network D_B] Total number of parameters : 2.765 M\n",
            "-----------------------------------------------\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Use an existing W&B account'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into https://api.wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find your API key here: https://wandb.ai/authorize?ref=models\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmichalness1\u001b[0m (\u001b[33mmichalness1-ben-gurion-university-of-the-negev\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ¢¿\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[38;5;178mâ£»\u001b[0m Waiting for wandb.init()...\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.23.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/cycleGAN/wandb/run-20251229_211919-dypk0ex6\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mchess_data_cyclegan\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/michalness1-ben-gurion-university-of-the-negev/CycleGAN-and-pix2pix\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/michalness1-ben-gurion-university-of-the-negev/CycleGAN-and-pix2pix/runs/dypk0ex6\u001b[0m\n",
            "create web directory checkpoints/chess_data_cyclegan/web...\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/content/cycleGAN/models/base_model.py:182: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\n",
            "Consider using tensor.detach() first. (Triggered internally at /pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:836.)\n",
            "  errors_ret[name] = float(getattr(self, \"loss_\" + name))  # float(...) works for both scalar tensor and float number\n",
            "[Rank 0] (epoch: 1, iters: 100, time: 0.644, data: 0.583) , D_A: 0.700, G_A: 0.983, cycle_A: 0.934, idt_A: 1.043, D_B: 0.371, G_B: 0.776, cycle_B: 2.071, idt_B: 0.445\n",
            "\n",
            "[Rank 0] (epoch: 1, iters: 200, time: 0.629, data: 0.002) , D_A: 0.168, G_A: 0.338, cycle_A: 0.901, idt_A: 0.659, D_B: 0.171, G_B: 0.568, cycle_B: 1.511, idt_B: 0.446\n",
            "\n",
            "[Rank 0] (epoch: 1, iters: 300, time: 0.637, data: 0.002) , D_A: 0.140, G_A: 0.561, cycle_A: 0.768, idt_A: 0.510, D_B: 0.181, G_B: 0.335, cycle_B: 1.136, idt_B: 0.363\n",
            "\n",
            "[Rank 0] (epoch: 1, iters: 400, time: 1.592, data: 0.002) , D_A: 0.277, G_A: 0.630, cycle_A: 0.675, idt_A: 1.032, D_B: 0.097, G_B: 0.391, cycle_B: 2.155, idt_B: 0.272\n",
            "\n",
            "[Rank 0] (epoch: 1, iters: 500, time: 0.635, data: 0.004) , D_A: 0.091, G_A: 1.101, cycle_A: 0.808, idt_A: 0.603, D_B: 0.195, G_B: 1.439, cycle_B: 1.468, idt_B: 0.317\n",
            "\n",
            "[Rank 0] (epoch: 1, iters: 600, time: 0.635, data: 0.002) , D_A: 0.083, G_A: 0.701, cycle_A: 0.687, idt_A: 0.479, D_B: 0.034, G_B: 0.909, cycle_B: 1.168, idt_B: 0.307\n",
            "\n",
            "[Rank 0] (epoch: 1, iters: 700, time: 0.634, data: 0.002) , D_A: 0.097, G_A: 0.852, cycle_A: 0.503, idt_A: 0.463, D_B: 0.156, G_B: 1.034, cycle_B: 0.978, idt_B: 0.229\n",
            "\n",
            "[Rank 0] (epoch: 1, iters: 800, time: 0.807, data: 0.002) , D_A: 0.295, G_A: 0.322, cycle_A: 0.563, idt_A: 0.458, D_B: 0.047, G_B: 0.625, cycle_B: 0.894, idt_B: 0.258\n",
            "\n",
            "[Rank 0] (epoch: 1, iters: 900, time: 0.636, data: 0.002) , D_A: 0.176, G_A: 0.794, cycle_A: 0.545, idt_A: 0.599, D_B: 0.054, G_B: 1.074, cycle_B: 1.467, idt_B: 0.253\n",
            "\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "End of epoch 1 / 200 \t Time Taken: 485 sec\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "[Rank 0] (epoch: 2, iters: 56, time: 0.639, data: 0.002) , D_A: 0.120, G_A: 0.514, cycle_A: 0.453, idt_A: 0.269, D_B: 0.070, G_B: 0.817, cycle_B: 1.069, idt_B: 0.208\n",
            "\n",
            "[Rank 0] (epoch: 2, iters: 156, time: 0.632, data: 0.004) , D_A: 0.088, G_A: 1.205, cycle_A: 0.442, idt_A: 0.261, D_B: 0.043, G_B: 0.760, cycle_B: 0.604, idt_B: 0.194\n",
            "\n",
            "[Rank 0] (epoch: 2, iters: 256, time: 0.983, data: 0.002) , D_A: 0.049, G_A: 0.864, cycle_A: 0.520, idt_A: 0.597, D_B: 0.061, G_B: 1.051, cycle_B: 1.008, idt_B: 0.236\n",
            "\n",
            "[Rank 0] (epoch: 2, iters: 356, time: 0.634, data: 0.002) , D_A: 0.034, G_A: 1.028, cycle_A: 0.947, idt_A: 0.531, D_B: 0.052, G_B: 1.034, cycle_B: 1.479, idt_B: 0.455\n",
            "\n",
            "[Rank 0] (epoch: 2, iters: 456, time: 0.633, data: 0.004) , D_A: 0.095, G_A: 1.142, cycle_A: 0.496, idt_A: 0.368, D_B: 0.039, G_B: 1.203, cycle_B: 0.836, idt_B: 0.195\n",
            "\n",
            "[Rank 0] (epoch: 2, iters: 556, time: 0.635, data: 0.002) , D_A: 0.056, G_A: 0.851, cycle_A: 0.443, idt_A: 0.379, D_B: 0.039, G_B: 0.718, cycle_B: 2.069, idt_B: 0.204\n",
            "\n",
            "[Rank 0] (epoch: 2, iters: 656, time: 0.899, data: 0.002) , D_A: 0.059, G_A: 0.716, cycle_A: 0.357, idt_A: 0.475, D_B: 0.020, G_B: 1.045, cycle_B: 1.021, idt_B: 0.156\n",
            "\n",
            "[Rank 0] (epoch: 2, iters: 756, time: 0.637, data: 0.002) , D_A: 0.064, G_A: 0.779, cycle_A: 0.409, idt_A: 0.416, D_B: 0.036, G_B: 1.026, cycle_B: 0.818, idt_B: 0.179\n",
            "\n",
            "[Rank 0] (epoch: 2, iters: 856, time: 0.636, data: 0.002) , D_A: 0.061, G_A: 0.594, cycle_A: 0.406, idt_A: 0.299, D_B: 0.037, G_B: 0.848, cycle_B: 0.703, idt_B: 0.169\n",
            "\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "End of epoch 2 / 200 \t Time Taken: 481 sec\n",
            "[Rank 0] (epoch: 3, iters: 12, time: 0.634, data: 0.002) , D_A: 0.047, G_A: 0.714, cycle_A: 0.297, idt_A: 0.279, D_B: 0.036, G_B: 0.932, cycle_B: 0.640, idt_B: 0.127\n",
            "\n",
            "[Rank 0] (epoch: 3, iters: 112, time: 1.024, data: 0.004) , D_A: 0.069, G_A: 0.595, cycle_A: 0.470, idt_A: 0.412, D_B: 0.070, G_B: 0.991, cycle_B: 1.000, idt_B: 0.197\n",
            "\n",
            "[Rank 0] (epoch: 3, iters: 212, time: 0.637, data: 0.002) , D_A: 0.064, G_A: 0.408, cycle_A: 0.393, idt_A: 0.382, D_B: 0.090, G_B: 0.689, cycle_B: 0.694, idt_B: 0.171\n",
            "\n",
            "[Rank 0] (epoch: 3, iters: 312, time: 0.631, data: 0.002) , D_A: 0.225, G_A: 0.271, cycle_A: 0.470, idt_A: 0.272, D_B: 0.042, G_B: 0.711, cycle_B: 0.845, idt_B: 0.197\n",
            "\n",
            "[Rank 0] (epoch: 3, iters: 412, time: 0.632, data: 0.002) , D_A: 0.218, G_A: 1.554, cycle_A: 0.608, idt_A: 0.650, D_B: 0.151, G_B: 1.063, cycle_B: 1.266, idt_B: 0.227\n",
            "\n",
            "[Rank 0] (epoch: 3, iters: 512, time: 0.830, data: 0.002) , D_A: 0.130, G_A: 1.113, cycle_A: 0.504, idt_A: 0.328, D_B: 0.024, G_B: 0.964, cycle_B: 0.775, idt_B: 0.193\n",
            "\n",
            "[Rank 0] (epoch: 3, iters: 612, time: 0.631, data: 0.002) , D_A: 0.092, G_A: 0.534, cycle_A: 0.425, idt_A: 0.297, D_B: 0.041, G_B: 0.766, cycle_B: 0.672, idt_B: 0.165\n",
            "\n",
            "[Rank 0] (epoch: 3, iters: 712, time: 0.637, data: 0.002) , D_A: 0.029, G_A: 1.050, cycle_A: 0.389, idt_A: 0.432, D_B: 0.066, G_B: 0.859, cycle_B: 1.293, idt_B: 0.147\n",
            "\n",
            "[Rank 0] (epoch: 3, iters: 812, time: 0.634, data: 0.002) , D_A: 0.028, G_A: 0.968, cycle_A: 0.334, idt_A: 0.356, D_B: 0.026, G_B: 0.987, cycle_B: 0.704, idt_B: 0.132\n",
            "\n",
            "[Rank 0] (epoch: 3, iters: 912, time: 0.834, data: 0.002) , D_A: 0.078, G_A: 0.770, cycle_A: 0.332, idt_A: 0.376, D_B: 0.038, G_B: 1.052, cycle_B: 0.865, idt_B: 0.141\n",
            "\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "End of epoch 3 / 200 \t Time Taken: 480 sec\n",
            "[Rank 0] (epoch: 4, iters: 68, time: 0.637, data: 0.002) , D_A: 0.235, G_A: 0.426, cycle_A: 0.324, idt_A: 0.419, D_B: 0.023, G_B: 1.506, cycle_B: 1.169, idt_B: 0.144\n",
            "\n",
            "[Rank 0] (epoch: 4, iters: 168, time: 0.637, data: 0.002) , D_A: 0.108, G_A: 1.359, cycle_A: 0.364, idt_A: 0.501, D_B: 0.054, G_B: 1.158, cycle_B: 2.165, idt_B: 0.159\n",
            "\n",
            "[Rank 0] (epoch: 4, iters: 268, time: 0.635, data: 0.002) , D_A: 0.207, G_A: 0.239, cycle_A: 0.408, idt_A: 0.300, D_B: 0.031, G_B: 0.949, cycle_B: 0.674, idt_B: 0.168\n",
            "\n",
            "[Rank 0] (epoch: 4, iters: 368, time: 1.186, data: 0.002) , D_A: 0.067, G_A: 0.774, cycle_A: 0.457, idt_A: 0.235, D_B: 0.041, G_B: 0.744, cycle_B: 0.570, idt_B: 0.196\n",
            "\n",
            "[Rank 0] (epoch: 4, iters: 468, time: 0.633, data: 0.004) , D_A: 0.063, G_A: 0.724, cycle_A: 0.318, idt_A: 0.209, D_B: 0.032, G_B: 0.756, cycle_B: 0.544, idt_B: 0.130\n",
            "\n",
            "[Rank 0] (epoch: 4, iters: 568, time: 0.634, data: 0.002) , D_A: 0.128, G_A: 1.871, cycle_A: 3.480, idt_A: 0.433, D_B: 0.275, G_B: 0.303, cycle_B: 1.764, idt_B: 1.790\n",
            "\n",
            "[Rank 0] (epoch: 4, iters: 668, time: 0.632, data: 0.002) , D_A: 0.015, G_A: 0.950, cycle_A: 0.818, idt_A: 0.276, D_B: 0.258, G_B: 0.290, cycle_B: 0.671, idt_B: 0.385\n",
            "\n",
            "[Rank 0] (epoch: 4, iters: 768, time: 0.849, data: 0.002) , D_A: 0.049, G_A: 0.940, cycle_A: 0.524, idt_A: 0.322, D_B: 0.195, G_B: 0.348, cycle_B: 0.631, idt_B: 0.252\n",
            "\n",
            "[Rank 0] (epoch: 4, iters: 868, time: 0.633, data: 0.002) , D_A: 0.033, G_A: 0.869, cycle_A: 0.516, idt_A: 0.440, D_B: 0.177, G_B: 0.387, cycle_B: 0.998, idt_B: 0.226\n",
            "\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "End of epoch 4 / 200 \t Time Taken: 481 sec\n",
            "[Rank 0] (epoch: 5, iters: 24, time: 0.634, data: 0.002) , D_A: 0.022, G_A: 0.715, cycle_A: 0.553, idt_A: 0.218, D_B: 0.260, G_B: 0.395, cycle_B: 0.724, idt_B: 0.240\n",
            "\n",
            "[Rank 0] (epoch: 5, iters: 124, time: 0.635, data: 0.003) , D_A: 0.016, G_A: 0.915, cycle_A: 0.412, idt_A: 0.295, D_B: 0.228, G_B: 0.489, cycle_B: 0.805, idt_B: 0.169\n",
            "\n",
            "[Rank 0] (epoch: 5, iters: 224, time: 1.037, data: 0.002) , D_A: 0.034, G_A: 0.722, cycle_A: 0.475, idt_A: 0.343, D_B: 0.242, G_B: 0.236, cycle_B: 0.707, idt_B: 0.200\n",
            "\n",
            "[Rank 0] (epoch: 5, iters: 324, time: 0.633, data: 0.002) , D_A: 0.105, G_A: 0.637, cycle_A: 0.402, idt_A: 0.246, D_B: 0.249, G_B: 0.439, cycle_B: 0.707, idt_B: 0.155\n",
            "\n",
            "[Rank 0] (epoch: 5, iters: 424, time: 0.635, data: 0.002) , D_A: 0.122, G_A: 0.363, cycle_A: 0.505, idt_A: 0.223, D_B: 0.147, G_B: 0.355, cycle_B: 0.534, idt_B: 0.204\n",
            "\n",
            "[Rank 0] (epoch: 5, iters: 524, time: 0.635, data: 0.002) , D_A: 0.087, G_A: 0.799, cycle_A: 0.311, idt_A: 0.400, D_B: 0.148, G_B: 0.582, cycle_B: 0.889, idt_B: 0.136\n",
            "\n",
            "[Rank 0] (epoch: 5, iters: 624, time: 0.889, data: 0.002) , D_A: 0.072, G_A: 0.738, cycle_A: 0.488, idt_A: 0.260, D_B: 0.118, G_B: 0.527, cycle_B: 0.574, idt_B: 0.216\n",
            "\n",
            "[Rank 0] (epoch: 5, iters: 724, time: 0.630, data: 0.002) , D_A: 0.233, G_A: 0.610, cycle_A: 0.333, idt_A: 0.281, D_B: 0.125, G_B: 0.599, cycle_B: 0.620, idt_B: 0.139\n",
            "\n",
            "[Rank 0] (epoch: 5, iters: 824, time: 0.634, data: 0.002) , D_A: 0.224, G_A: 0.808, cycle_A: 0.457, idt_A: 0.190, D_B: 0.101, G_B: 0.554, cycle_B: 0.455, idt_B: 0.183\n",
            "\n",
            "[Rank 0] (epoch: 5, iters: 924, time: 0.636, data: 0.002) , D_A: 0.212, G_A: 0.210, cycle_A: 0.431, idt_A: 0.236, D_B: 0.168, G_B: 0.379, cycle_B: 0.524, idt_B: 0.178\n",
            "\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "saving the model at the end of epoch 5, iters 4720\n",
            "End of epoch 5 / 200 \t Time Taken: 481 sec\n",
            "[Rank 0] (epoch: 6, iters: 80, time: 1.046, data: 0.003) , D_A: 0.234, G_A: 1.811, cycle_A: 0.398, idt_A: 0.266, D_B: 0.066, G_B: 0.863, cycle_B: 0.712, idt_B: 0.204\n",
            "\n",
            "[Rank 0] (epoch: 6, iters: 180, time: 0.635, data: 0.002) , D_A: 0.257, G_A: 0.447, cycle_A: 0.847, idt_A: 1.249, D_B: 0.062, G_B: 1.041, cycle_B: 2.373, idt_B: 0.239\n",
            "\n",
            "[Rank 0] (epoch: 6, iters: 280, time: 0.634, data: 0.004) , D_A: 0.162, G_A: 0.431, cycle_A: 0.404, idt_A: 0.694, D_B: 0.057, G_B: 0.956, cycle_B: 1.409, idt_B: 0.151\n",
            "\n",
            "saving the latest model (epoch 6, total_iters 5000)\n",
            "[Rank 0] (epoch: 6, iters: 380, time: 0.636, data: 0.002) , D_A: 0.123, G_A: 0.914, cycle_A: 0.408, idt_A: 0.654, D_B: 0.064, G_B: 0.942, cycle_B: 1.030, idt_B: 0.172\n",
            "\n",
            "[Rank 0] (epoch: 6, iters: 480, time: 0.825, data: 0.002) , D_A: 0.055, G_A: 0.600, cycle_A: 0.289, idt_A: 0.507, D_B: 0.024, G_B: 0.646, cycle_B: 0.928, idt_B: 0.124\n",
            "\n",
            "[Rank 0] (epoch: 6, iters: 580, time: 0.633, data: 0.002) , D_A: 0.051, G_A: 0.631, cycle_A: 0.338, idt_A: 0.413, D_B: 0.085, G_B: 0.505, cycle_B: 0.780, idt_B: 0.139\n",
            "\n",
            "[Rank 0] (epoch: 6, iters: 680, time: 0.633, data: 0.004) , D_A: 0.034, G_A: 0.668, cycle_A: 0.427, idt_A: 0.499, D_B: 0.036, G_B: 0.980, cycle_B: 1.211, idt_B: 0.180\n",
            "\n",
            "[Rank 0] (epoch: 6, iters: 780, time: 0.634, data: 0.002) , D_A: 0.050, G_A: 0.871, cycle_A: 0.287, idt_A: 0.547, D_B: 0.031, G_B: 0.710, cycle_B: 0.928, idt_B: 0.120\n",
            "\n",
            "[Rank 0] (epoch: 6, iters: 880, time: 0.901, data: 0.003) , D_A: 0.065, G_A: 0.772, cycle_A: 0.275, idt_A: 0.314, D_B: 0.026, G_B: 0.805, cycle_B: 0.537, idt_B: 0.106\n",
            "\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "End of epoch 6 / 200 \t Time Taken: 480 sec\n",
            "[Rank 0] (epoch: 7, iters: 36, time: 0.634, data: 0.002) , D_A: 0.049, G_A: 0.666, cycle_A: 0.335, idt_A: 0.298, D_B: 0.106, G_B: 0.751, cycle_B: 0.742, idt_B: 0.137\n",
            "\n",
            "[Rank 0] (epoch: 7, iters: 136, time: 0.632, data: 0.002) , D_A: 0.053, G_A: 1.020, cycle_A: 0.513, idt_A: 0.329, D_B: 0.041, G_B: 1.021, cycle_B: 0.710, idt_B: 0.236\n",
            "\n",
            "[Rank 0] (epoch: 7, iters: 236, time: 0.635, data: 0.002) , D_A: 0.018, G_A: 0.531, cycle_A: 0.350, idt_A: 0.296, D_B: 0.064, G_B: 0.565, cycle_B: 0.674, idt_B: 0.150\n",
            "\n",
            "[Rank 0] (epoch: 7, iters: 336, time: 1.058, data: 0.002) , D_A: 0.056, G_A: 0.648, cycle_A: 0.261, idt_A: 0.225, D_B: 0.079, G_B: 0.534, cycle_B: 0.508, idt_B: 0.107\n",
            "\n",
            "[Rank 0] (epoch: 7, iters: 436, time: 0.636, data: 0.002) , D_A: 0.046, G_A: 0.611, cycle_A: 0.282, idt_A: 0.209, D_B: 0.031, G_B: 0.494, cycle_B: 0.478, idt_B: 0.122\n",
            "\n",
            "[Rank 0] (epoch: 7, iters: 536, time: 0.635, data: 0.002) , D_A: 0.029, G_A: 0.902, cycle_A: 0.284, idt_A: 0.194, D_B: 0.055, G_B: 0.722, cycle_B: 0.511, idt_B: 0.119\n",
            "\n",
            "[Rank 0] (epoch: 7, iters: 636, time: 0.633, data: 0.005) , D_A: 0.016, G_A: 0.803, cycle_A: 0.297, idt_A: 0.193, D_B: 0.034, G_B: 0.748, cycle_B: 0.467, idt_B: 0.118\n",
            "\n",
            "[Rank 0] (epoch: 7, iters: 736, time: 0.835, data: 0.002) , D_A: 0.111, G_A: 0.589, cycle_A: 0.263, idt_A: 0.269, D_B: 0.036, G_B: 0.879, cycle_B: 0.623, idt_B: 0.097\n",
            "\n",
            "[Rank 0] (epoch: 7, iters: 836, time: 0.632, data: 0.002) , D_A: 0.141, G_A: 0.498, cycle_A: 0.280, idt_A: 0.294, D_B: 0.058, G_B: 0.930, cycle_B: 0.592, idt_B: 0.109\n",
            "\n",
            "[Rank 0] (epoch: 7, iters: 936, time: 0.634, data: 0.002) , D_A: 0.153, G_A: 0.844, cycle_A: 0.285, idt_A: 0.230, D_B: 0.055, G_B: 0.649, cycle_B: 0.545, idt_B: 0.106\n",
            "\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "End of epoch 7 / 200 \t Time Taken: 480 sec\n",
            "[Rank 0] (epoch: 8, iters: 92, time: 0.636, data: 0.002) , D_A: 0.040, G_A: 0.801, cycle_A: 0.269, idt_A: 0.347, D_B: 0.051, G_B: 0.631, cycle_B: 0.625, idt_B: 0.089\n",
            "\n",
            "[Rank 0] (epoch: 8, iters: 192, time: 1.059, data: 0.002) , D_A: 0.093, G_A: 0.796, cycle_A: 0.269, idt_A: 0.222, D_B: 0.039, G_B: 0.677, cycle_B: 0.503, idt_B: 0.081\n",
            "\n",
            "[Rank 0] (epoch: 8, iters: 292, time: 0.635, data: 0.002) , D_A: 0.139, G_A: 0.812, cycle_A: 0.215, idt_A: 0.269, D_B: 0.021, G_B: 1.021, cycle_B: 0.591, idt_B: 0.077\n",
            "\n",
            "[Rank 0] (epoch: 8, iters: 392, time: 0.636, data: 0.002) , D_A: 0.214, G_A: 0.469, cycle_A: 0.258, idt_A: 0.350, D_B: 0.028, G_B: 0.950, cycle_B: 0.699, idt_B: 0.094\n",
            "\n",
            "[Rank 0] (epoch: 8, iters: 492, time: 0.633, data: 0.002) , D_A: 0.056, G_A: 0.764, cycle_A: 0.309, idt_A: 0.265, D_B: 0.082, G_B: 0.693, cycle_B: 0.644, idt_B: 0.114\n",
            "\n",
            "[Rank 0] (epoch: 8, iters: 592, time: 0.870, data: 0.002) , D_A: 0.073, G_A: 0.709, cycle_A: 0.406, idt_A: 0.231, D_B: 0.254, G_B: 0.260, cycle_B: 0.640, idt_B: 0.181\n",
            "\n",
            "[Rank 0] (epoch: 8, iters: 692, time: 0.634, data: 0.002) , D_A: 0.115, G_A: 0.700, cycle_A: 0.351, idt_A: 0.325, D_B: 0.046, G_B: 1.207, cycle_B: 1.375, idt_B: 0.139\n",
            "\n",
            "[Rank 0] (epoch: 8, iters: 792, time: 0.632, data: 0.002) , D_A: 0.048, G_A: 0.615, cycle_A: 0.242, idt_A: 0.191, D_B: 0.060, G_B: 0.905, cycle_B: 0.459, idt_B: 0.078\n",
            "\n",
            "[Rank 0] (epoch: 8, iters: 892, time: 0.634, data: 0.002) , D_A: 0.079, G_A: 0.562, cycle_A: 0.243, idt_A: 0.416, D_B: 0.016, G_B: 0.958, cycle_B: 0.591, idt_B: 0.090\n",
            "\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "End of epoch 8 / 200 \t Time Taken: 481 sec\n",
            "[Rank 0] (epoch: 9, iters: 48, time: 1.098, data: 0.002) , D_A: 0.036, G_A: 0.829, cycle_A: 0.231, idt_A: 0.193, D_B: 0.024, G_B: 0.825, cycle_B: 0.481, idt_B: 0.093\n",
            "\n",
            "[Rank 0] (epoch: 9, iters: 148, time: 0.636, data: 0.002) , D_A: 0.053, G_A: 0.582, cycle_A: 0.284, idt_A: 0.217, D_B: 0.067, G_B: 0.933, cycle_B: 0.495, idt_B: 0.104\n",
            "\n",
            "[Rank 0] (epoch: 9, iters: 248, time: 0.634, data: 0.003) , D_A: 0.096, G_A: 1.250, cycle_A: 0.250, idt_A: 0.192, D_B: 0.055, G_B: 1.124, cycle_B: 0.427, idt_B: 0.099\n",
            "\n",
            "[Rank 0] (epoch: 9, iters: 348, time: 0.636, data: 0.002) , D_A: 0.042, G_A: 0.782, cycle_A: 0.247, idt_A: 0.250, D_B: 0.024, G_B: 0.886, cycle_B: 0.690, idt_B: 0.144\n",
            "\n",
            "[Rank 0] (epoch: 9, iters: 448, time: 1.054, data: 0.002) , D_A: 0.063, G_A: 0.744, cycle_A: 0.328, idt_A: 0.227, D_B: 0.043, G_B: 0.703, cycle_B: 0.550, idt_B: 0.130\n",
            "\n",
            "[Rank 0] (epoch: 9, iters: 548, time: 0.636, data: 0.002) , D_A: 0.028, G_A: 0.879, cycle_A: 0.236, idt_A: 0.363, D_B: 0.062, G_B: 0.987, cycle_B: 0.594, idt_B: 0.100\n",
            "\n",
            "[Rank 0] (epoch: 9, iters: 648, time: 0.633, data: 0.002) , D_A: 0.068, G_A: 0.701, cycle_A: 0.419, idt_A: 0.330, D_B: 0.043, G_B: 0.937, cycle_B: 0.901, idt_B: 0.186\n",
            "\n",
            "[Rank 0] (epoch: 9, iters: 748, time: 0.631, data: 0.002) , D_A: 0.036, G_A: 0.717, cycle_A: 0.322, idt_A: 0.297, D_B: 0.129, G_B: 1.286, cycle_B: 0.880, idt_B: 0.127\n",
            "\n",
            "[Rank 0] (epoch: 9, iters: 848, time: 0.841, data: 0.003) , D_A: 0.064, G_A: 0.590, cycle_A: 0.318, idt_A: 0.202, D_B: 0.031, G_B: 1.239, cycle_B: 0.468, idt_B: 0.123\n",
            "\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "End of epoch 9 / 200 \t Time Taken: 481 sec\n",
            "[Rank 0] (epoch: 10, iters: 4, time: 0.637, data: 0.002) , D_A: 0.075, G_A: 0.623, cycle_A: 0.300, idt_A: 0.238, D_B: 0.071, G_B: 0.477, cycle_B: 0.496, idt_B: 0.115\n",
            "\n",
            "[Rank 0] (epoch: 10, iters: 104, time: 0.632, data: 0.003) , D_A: 0.218, G_A: 0.861, cycle_A: 0.288, idt_A: 0.226, D_B: 0.045, G_B: 0.568, cycle_B: 0.550, idt_B: 0.126\n",
            "\n",
            "[Rank 0] (epoch: 10, iters: 204, time: 0.633, data: 0.004) , D_A: 0.091, G_A: 0.743, cycle_A: 0.354, idt_A: 0.302, D_B: 0.078, G_B: 0.827, cycle_B: 0.677, idt_B: 0.127\n",
            "\n",
            "[Rank 0] (epoch: 10, iters: 304, time: 1.084, data: 0.002) , D_A: 0.250, G_A: 0.839, cycle_A: 0.270, idt_A: 0.238, D_B: 0.035, G_B: 0.918, cycle_B: 0.584, idt_B: 0.099\n",
            "\n",
            "[Rank 0] (epoch: 10, iters: 404, time: 0.633, data: 0.002) , D_A: 0.088, G_A: 0.572, cycle_A: 0.348, idt_A: 0.238, D_B: 0.084, G_B: 0.776, cycle_B: 0.548, idt_B: 0.133\n",
            "\n",
            "[Rank 0] (epoch: 10, iters: 504, time: 0.637, data: 0.003) , D_A: 0.110, G_A: 0.305, cycle_A: 0.269, idt_A: 0.315, D_B: 0.146, G_B: 0.335, cycle_B: 0.615, idt_B: 0.103\n",
            "\n",
            "[Rank 0] (epoch: 10, iters: 604, time: 0.631, data: 0.002) , D_A: 0.071, G_A: 0.527, cycle_A: 0.233, idt_A: 0.212, D_B: 0.044, G_B: 0.565, cycle_B: 0.553, idt_B: 0.085\n",
            "\n",
            "[Rank 0] (epoch: 10, iters: 704, time: 0.934, data: 0.002) , D_A: 0.048, G_A: 0.489, cycle_A: 0.322, idt_A: 0.179, D_B: 0.026, G_B: 0.596, cycle_B: 0.481, idt_B: 0.125\n",
            "\n",
            "[Rank 0] (epoch: 10, iters: 804, time: 0.636, data: 0.003) , D_A: 0.159, G_A: 0.856, cycle_A: 0.277, idt_A: 0.188, D_B: 0.022, G_B: 0.604, cycle_B: 0.461, idt_B: 0.103\n",
            "\n",
            "[Rank 0] (epoch: 10, iters: 904, time: 0.631, data: 0.002) , D_A: 0.279, G_A: 0.618, cycle_A: 0.297, idt_A: 0.201, D_B: 0.051, G_B: 0.915, cycle_B: 0.582, idt_B: 0.109\n",
            "\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "saving the model at the end of epoch 10, iters 9440\n",
            "End of epoch 10 / 200 \t Time Taken: 480 sec\n",
            "[Rank 0] (epoch: 11, iters: 60, time: 0.635, data: 0.002) , D_A: 0.047, G_A: 0.734, cycle_A: 0.390, idt_A: 0.467, D_B: 0.100, G_B: 0.607, cycle_B: 0.786, idt_B: 0.156\n",
            "\n",
            "[Rank 0] (epoch: 11, iters: 160, time: 1.083, data: 0.002) , D_A: 0.310, G_A: 0.570, cycle_A: 0.285, idt_A: 0.208, D_B: 0.047, G_B: 0.849, cycle_B: 0.512, idt_B: 0.091\n",
            "\n",
            "[Rank 0] (epoch: 11, iters: 260, time: 0.635, data: 0.002) , D_A: 0.123, G_A: 0.433, cycle_A: 0.332, idt_A: 0.169, D_B: 0.063, G_B: 0.924, cycle_B: 0.440, idt_B: 0.126\n",
            "\n",
            "[Rank 0] (epoch: 11, iters: 360, time: 0.635, data: 0.002) , D_A: 0.138, G_A: 0.506, cycle_A: 0.275, idt_A: 0.180, D_B: 0.099, G_B: 1.031, cycle_B: 0.407, idt_B: 0.108\n",
            "\n",
            "[Rank 0] (epoch: 11, iters: 460, time: 0.632, data: 0.002) , D_A: 0.102, G_A: 0.155, cycle_A: 0.292, idt_A: 0.195, D_B: 0.079, G_B: 0.305, cycle_B: 0.496, idt_B: 0.120\n",
            "\n",
            "[Rank 0] (epoch: 11, iters: 560, time: 1.069, data: 0.002) , D_A: 0.116, G_A: 0.143, cycle_A: 0.353, idt_A: 0.195, D_B: 0.068, G_B: 0.583, cycle_B: 0.495, idt_B: 0.133\n",
            "\n",
            "saving the latest model (epoch 11, total_iters 10000)\n",
            "[Rank 0] (epoch: 11, iters: 660, time: 0.633, data: 0.002) , D_A: 0.128, G_A: 0.321, cycle_A: 0.297, idt_A: 0.206, D_B: 0.017, G_B: 0.789, cycle_B: 0.520, idt_B: 0.117\n",
            "\n",
            "[Rank 0] (epoch: 11, iters: 760, time: 0.635, data: 0.004) , D_A: 0.106, G_A: 0.491, cycle_A: 0.275, idt_A: 0.210, D_B: 0.017, G_B: 1.148, cycle_B: 0.553, idt_B: 0.103\n",
            "\n",
            "[Rank 0] (epoch: 11, iters: 860, time: 0.632, data: 0.002) , D_A: 0.118, G_A: 0.503, cycle_A: 0.314, idt_A: 0.215, D_B: 0.040, G_B: 0.680, cycle_B: 0.552, idt_B: 0.117\n",
            "\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "End of epoch 11 / 200 \t Time Taken: 480 sec\n",
            "[Rank 0] (epoch: 12, iters: 16, time: 1.205, data: 0.002) , D_A: 0.138, G_A: 0.690, cycle_A: 0.343, idt_A: 0.182, D_B: 0.018, G_B: 0.901, cycle_B: 0.455, idt_B: 0.120\n",
            "\n",
            "[Rank 0] (epoch: 12, iters: 116, time: 0.636, data: 0.002) , D_A: 0.154, G_A: 1.408, cycle_A: 0.294, idt_A: 0.230, D_B: 0.035, G_B: 0.718, cycle_B: 0.600, idt_B: 0.096\n",
            "\n",
            "[Rank 0] (epoch: 12, iters: 216, time: 0.638, data: 0.002) , D_A: 0.384, G_A: 0.691, cycle_A: 0.254, idt_A: 0.237, D_B: 0.016, G_B: 0.979, cycle_B: 0.575, idt_B: 0.097\n",
            "\n",
            "[Rank 0] (epoch: 12, iters: 316, time: 0.631, data: 0.002) , D_A: 0.284, G_A: 0.231, cycle_A: 0.302, idt_A: 0.281, D_B: 0.061, G_B: 0.820, cycle_B: 0.895, idt_B: 0.117\n",
            "\n",
            "[Rank 0] (epoch: 12, iters: 416, time: 0.856, data: 0.004) , D_A: 0.104, G_A: 1.016, cycle_A: 0.308, idt_A: 0.174, D_B: 0.023, G_B: 0.860, cycle_B: 0.425, idt_B: 0.118\n",
            "\n",
            "[Rank 0] (epoch: 12, iters: 516, time: 0.636, data: 0.002) , D_A: 0.108, G_A: 0.864, cycle_A: 0.388, idt_A: 0.243, D_B: 0.037, G_B: 0.686, cycle_B: 0.568, idt_B: 0.117\n",
            "\n",
            "[Rank 0] (epoch: 12, iters: 616, time: 0.631, data: 0.003) , D_A: 0.168, G_A: 0.680, cycle_A: 0.435, idt_A: 0.306, D_B: 0.024, G_B: 1.698, cycle_B: 2.296, idt_B: 0.152\n",
            "\n",
            "[Rank 0] (epoch: 12, iters: 716, time: 0.633, data: 0.002) , D_A: 0.291, G_A: 0.121, cycle_A: 0.294, idt_A: 0.216, D_B: 0.041, G_B: 0.875, cycle_B: 0.514, idt_B: 0.114\n",
            "\n",
            "[Rank 0] (epoch: 12, iters: 816, time: 0.867, data: 0.003) , D_A: 0.050, G_A: 0.062, cycle_A: 0.210, idt_A: 0.175, D_B: 0.014, G_B: 0.941, cycle_B: 0.432, idt_B: 0.076\n",
            "\n",
            "[Rank 0] (epoch: 12, iters: 916, time: 0.636, data: 0.003) , D_A: 0.080, G_A: 0.884, cycle_A: 0.264, idt_A: 0.230, D_B: 0.021, G_B: 0.605, cycle_B: 0.580, idt_B: 0.090\n",
            "\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "End of epoch 12 / 200 \t Time Taken: 480 sec\n",
            "[Rank 0] (epoch: 13, iters: 72, time: 0.632, data: 0.004) , D_A: 0.091, G_A: 0.432, cycle_A: 0.236, idt_A: 0.281, D_B: 0.024, G_B: 0.939, cycle_B: 1.038, idt_B: 0.087\n",
            "\n",
            "[Rank 0] (epoch: 13, iters: 172, time: 0.634, data: 0.002) , D_A: 0.218, G_A: 0.522, cycle_A: 0.311, idt_A: 0.287, D_B: 0.058, G_B: 0.562, cycle_B: 0.822, idt_B: 0.113\n",
            "\n",
            "[Rank 0] (epoch: 13, iters: 272, time: 1.236, data: 0.002) , D_A: 0.047, G_A: 0.285, cycle_A: 0.252, idt_A: 0.288, D_B: 0.018, G_B: 0.826, cycle_B: 0.613, idt_B: 0.083\n",
            "\n",
            "[Rank 0] (epoch: 13, iters: 372, time: 0.631, data: 0.002) , D_A: 0.169, G_A: 0.703, cycle_A: 0.199, idt_A: 0.254, D_B: 0.035, G_B: 0.765, cycle_B: 0.592, idt_B: 0.063\n",
            "\n",
            "[Rank 0] (epoch: 13, iters: 472, time: 0.638, data: 0.002) , D_A: 0.247, G_A: 0.164, cycle_A: 0.226, idt_A: 0.196, D_B: 0.016, G_B: 0.803, cycle_B: 0.460, idt_B: 0.080\n",
            "\n",
            "[Rank 0] (epoch: 13, iters: 572, time: 0.631, data: 0.002) , D_A: 0.080, G_A: 0.204, cycle_A: 0.198, idt_A: 0.142, D_B: 0.037, G_B: 0.877, cycle_B: 0.379, idt_B: 0.076\n",
            "\n",
            "[Rank 0] (epoch: 13, iters: 672, time: 1.070, data: 0.004) , D_A: 0.243, G_A: 0.181, cycle_A: 0.245, idt_A: 0.200, D_B: 0.714, G_B: 0.770, cycle_B: 0.512, idt_B: 0.088\n",
            "\n",
            "[Rank 0] (epoch: 13, iters: 772, time: 0.633, data: 0.002) , D_A: 0.150, G_A: 0.519, cycle_A: 0.235, idt_A: 0.229, D_B: 0.310, G_B: 0.142, cycle_B: 0.486, idt_B: 0.088\n",
            "\n",
            "[Rank 0] (epoch: 13, iters: 872, time: 0.631, data: 0.002) , D_A: 0.170, G_A: 0.426, cycle_A: 0.288, idt_A: 0.243, D_B: 0.061, G_B: 0.622, cycle_B: 0.618, idt_B: 0.104\n",
            "\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "End of epoch 13 / 200 \t Time Taken: 481 sec\n",
            "[Rank 0] (epoch: 14, iters: 28, time: 0.637, data: 0.004) , D_A: 0.215, G_A: 0.593, cycle_A: 0.216, idt_A: 0.298, D_B: 0.263, G_B: 0.974, cycle_B: 0.609, idt_B: 0.076\n",
            "\n",
            "[Rank 0] (epoch: 14, iters: 128, time: 1.071, data: 0.002) , D_A: 0.023, G_A: 0.795, cycle_A: 0.263, idt_A: 0.228, D_B: 0.102, G_B: 0.481, cycle_B: 0.537, idt_B: 0.097\n",
            "\n",
            "[Rank 0] (epoch: 14, iters: 228, time: 0.636, data: 0.002) , D_A: 0.021, G_A: 0.801, cycle_A: 0.214, idt_A: 0.261, D_B: 0.199, G_B: 0.928, cycle_B: 0.620, idt_B: 0.075\n",
            "\n",
            "[Rank 0] (epoch: 14, iters: 328, time: 0.635, data: 0.003) , D_A: 0.022, G_A: 0.953, cycle_A: 0.214, idt_A: 0.206, D_B: 0.224, G_B: 0.364, cycle_B: 0.509, idt_B: 0.068\n",
            "\n",
            "[Rank 0] (epoch: 14, iters: 428, time: 0.633, data: 0.002) , D_A: 0.049, G_A: 0.868, cycle_A: 0.269, idt_A: 0.402, D_B: 0.037, G_B: 1.073, cycle_B: 0.817, idt_B: 0.103\n",
            "\n",
            "[Rank 0] (epoch: 14, iters: 528, time: 0.867, data: 0.004) , D_A: 0.014, G_A: 0.731, cycle_A: 0.215, idt_A: 0.216, D_B: 0.147, G_B: 0.381, cycle_B: 0.534, idt_B: 0.077\n",
            "\n",
            "[Rank 0] (epoch: 14, iters: 628, time: 0.636, data: 0.002) , D_A: 0.029, G_A: 0.847, cycle_A: 0.289, idt_A: 0.228, D_B: 0.236, G_B: 0.143, cycle_B: 1.103, idt_B: 0.102\n",
            "\n",
            "[Rank 0] (epoch: 14, iters: 728, time: 0.635, data: 0.002) , D_A: 0.036, G_A: 1.107, cycle_A: 0.236, idt_A: 0.177, D_B: 0.093, G_B: 0.310, cycle_B: 0.402, idt_B: 0.095\n",
            "\n",
            "[Rank 0] (epoch: 14, iters: 828, time: 0.633, data: 0.002) , D_A: 0.043, G_A: 0.690, cycle_A: 0.237, idt_A: 0.221, D_B: 0.093, G_B: 0.497, cycle_B: 0.535, idt_B: 0.089\n",
            "\n",
            "[Rank 0] (epoch: 14, iters: 928, time: 0.842, data: 0.002) , D_A: 0.155, G_A: 0.752, cycle_A: 0.335, idt_A: 0.325, D_B: 0.117, G_B: 0.640, cycle_B: 1.025, idt_B: 0.136\n",
            "\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "End of epoch 14 / 200 \t Time Taken: 481 sec\n",
            "[Rank 0] (epoch: 15, iters: 84, time: 0.636, data: 0.002) , D_A: 0.290, G_A: 0.517, cycle_A: 0.216, idt_A: 0.287, D_B: 0.034, G_B: 0.465, cycle_B: 0.649, idt_B: 0.079\n",
            "\n",
            "[Rank 0] (epoch: 15, iters: 184, time: 0.636, data: 0.003) , D_A: 0.252, G_A: 0.047, cycle_A: 0.304, idt_A: 0.267, D_B: 0.231, G_B: 0.248, cycle_B: 0.607, idt_B: 0.110\n",
            "\n",
            "[Rank 0] (epoch: 15, iters: 284, time: 0.636, data: 0.004) , D_A: 0.161, G_A: 0.228, cycle_A: 0.206, idt_A: 0.202, D_B: 0.130, G_B: 0.468, cycle_B: 0.539, idt_B: 0.069\n",
            "\n",
            "[Rank 0] (epoch: 15, iters: 384, time: 1.102, data: 0.002) , D_A: 0.166, G_A: 0.280, cycle_A: 0.207, idt_A: 0.182, D_B: 0.185, G_B: 0.242, cycle_B: 0.471, idt_B: 0.076\n",
            "\n",
            "[Rank 0] (epoch: 15, iters: 484, time: 0.634, data: 0.002) , D_A: 0.130, G_A: 0.184, cycle_A: 0.278, idt_A: 0.270, D_B: 0.209, G_B: 0.636, cycle_B: 0.662, idt_B: 0.107\n",
            "\n",
            "[Rank 0] (epoch: 15, iters: 584, time: 0.634, data: 0.004) , D_A: 0.219, G_A: 0.545, cycle_A: 0.239, idt_A: 0.179, D_B: 0.079, G_B: 0.234, cycle_B: 0.459, idt_B: 0.093\n",
            "\n",
            "[Rank 0] (epoch: 15, iters: 684, time: 0.635, data: 0.002) , D_A: 0.330, G_A: 0.227, cycle_A: 0.174, idt_A: 0.353, D_B: 0.267, G_B: 0.162, cycle_B: 0.946, idt_B: 0.067\n",
            "\n",
            "[Rank 0] (epoch: 15, iters: 784, time: 1.222, data: 0.002) , D_A: 0.249, G_A: 0.454, cycle_A: 0.326, idt_A: 0.204, D_B: 0.205, G_B: 1.129, cycle_B: 0.587, idt_B: 0.120\n",
            "\n",
            "[Rank 0] (epoch: 15, iters: 884, time: 0.635, data: 0.002) , D_A: 0.199, G_A: 0.706, cycle_A: 0.202, idt_A: 0.406, D_B: 0.141, G_B: 0.856, cycle_B: 0.918, idt_B: 0.081\n",
            "\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "saving the model at the end of epoch 15, iters 14160\n",
            "End of epoch 15 / 200 \t Time Taken: 481 sec\n",
            "[Rank 0] (epoch: 16, iters: 40, time: 0.637, data: 0.002) , D_A: 0.403, G_A: 0.705, cycle_A: 0.289, idt_A: 0.175, D_B: 0.082, G_B: 0.367, cycle_B: 0.431, idt_B: 0.110\n",
            "\n",
            "[Rank 0] (epoch: 16, iters: 140, time: 0.634, data: 0.002) , D_A: 0.188, G_A: 0.319, cycle_A: 0.284, idt_A: 0.147, D_B: 0.090, G_B: 0.613, cycle_B: 0.444, idt_B: 0.113\n",
            "\n",
            "[Rank 0] (epoch: 16, iters: 240, time: 1.113, data: 0.002) , D_A: 0.482, G_A: 0.955, cycle_A: 0.251, idt_A: 0.146, D_B: 0.149, G_B: 0.783, cycle_B: 0.363, idt_B: 0.090\n",
            "\n",
            "[Rank 0] (epoch: 16, iters: 340, time: 0.632, data: 0.002) , D_A: 0.264, G_A: 0.525, cycle_A: 0.185, idt_A: 0.181, D_B: 0.084, G_B: 0.659, cycle_B: 0.486, idt_B: 0.074\n",
            "\n",
            "[Rank 0] (epoch: 16, iters: 440, time: 0.635, data: 0.002) , D_A: 0.454, G_A: 0.024, cycle_A: 0.265, idt_A: 0.192, D_B: 0.118, G_B: 0.617, cycle_B: 0.500, idt_B: 0.105\n",
            "\n",
            "[Rank 0] (epoch: 16, iters: 540, time: 0.630, data: 0.002) , D_A: 0.192, G_A: 0.436, cycle_A: 0.569, idt_A: 0.370, D_B: 0.074, G_B: 0.747, cycle_B: 0.893, idt_B: 0.271\n",
            "\n",
            "[Rank 0] (epoch: 16, iters: 640, time: 0.847, data: 0.002) , D_A: 0.042, G_A: 0.617, cycle_A: 0.334, idt_A: 0.214, D_B: 0.029, G_B: 0.264, cycle_B: 0.517, idt_B: 0.114\n",
            "\n",
            "[Rank 0] (epoch: 16, iters: 740, time: 0.629, data: 0.002) , D_A: 0.223, G_A: 0.703, cycle_A: 0.277, idt_A: 0.200, D_B: 0.131, G_B: 0.990, cycle_B: 0.499, idt_B: 0.108\n",
            "\n",
            "[Rank 0] (epoch: 16, iters: 840, time: 0.639, data: 0.002) , D_A: 0.175, G_A: 1.301, cycle_A: 0.244, idt_A: 0.216, D_B: 0.054, G_B: 0.605, cycle_B: 0.655, idt_B: 0.095\n",
            "\n",
            "saving the latest model (epoch 16, total_iters 15000)\n",
            "[Rank 0] (epoch: 16, iters: 940, time: 0.632, data: 0.002) , D_A: 0.035, G_A: 1.110, cycle_A: 0.246, idt_A: 0.183, D_B: 0.199, G_B: 0.217, cycle_B: 0.530, idt_B: 0.091\n",
            "\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "End of epoch 16 / 200 \t Time Taken: 480 sec\n",
            "[Rank 0] (epoch: 17, iters: 96, time: 1.277, data: 0.002) , D_A: 0.063, G_A: 1.146, cycle_A: 0.261, idt_A: 0.280, D_B: 0.376, G_B: 1.016, cycle_B: 0.596, idt_B: 0.104\n",
            "\n",
            "[Rank 0] (epoch: 17, iters: 196, time: 0.638, data: 0.004) , D_A: 0.068, G_A: 0.685, cycle_A: 0.290, idt_A: 0.186, D_B: 0.052, G_B: 0.573, cycle_B: 0.458, idt_B: 0.111\n",
            "\n",
            "[Rank 0] (epoch: 17, iters: 296, time: 0.629, data: 0.002) , D_A: 0.049, G_A: 0.598, cycle_A: 0.227, idt_A: 0.190, D_B: 0.030, G_B: 0.651, cycle_B: 0.523, idt_B: 0.086\n",
            "\n",
            "[Rank 0] (epoch: 17, iters: 396, time: 0.638, data: 0.002) , D_A: 0.058, G_A: 0.708, cycle_A: 0.310, idt_A: 0.157, D_B: 0.036, G_B: 0.659, cycle_B: 0.478, idt_B: 0.117\n",
            "\n",
            "[Rank 0] (epoch: 17, iters: 496, time: 0.862, data: 0.002) , D_A: 0.059, G_A: 0.731, cycle_A: 0.185, idt_A: 0.194, D_B: 0.105, G_B: 0.685, cycle_B: 0.516, idt_B: 0.068\n",
            "\n",
            "[Rank 0] (epoch: 17, iters: 596, time: 0.636, data: 0.002) , D_A: 0.046, G_A: 0.647, cycle_A: 0.297, idt_A: 0.195, D_B: 0.104, G_B: 0.395, cycle_B: 0.521, idt_B: 0.115\n",
            "\n",
            "[Rank 0] (epoch: 17, iters: 696, time: 0.630, data: 0.002) , D_A: 0.058, G_A: 0.544, cycle_A: 0.297, idt_A: 0.176, D_B: 0.097, G_B: 0.874, cycle_B: 0.499, idt_B: 0.118\n",
            "\n",
            "[Rank 0] (epoch: 17, iters: 796, time: 0.636, data: 0.002) , D_A: 0.133, G_A: 0.243, cycle_A: 0.292, idt_A: 0.142, D_B: 0.206, G_B: 0.763, cycle_B: 0.399, idt_B: 0.123\n",
            "\n",
            "[Rank 0] (epoch: 17, iters: 896, time: 1.257, data: 0.002) , D_A: 0.091, G_A: 0.785, cycle_A: 0.241, idt_A: 0.174, D_B: 0.084, G_B: 0.435, cycle_B: 0.504, idt_B: 0.096\n",
            "\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "End of epoch 17 / 200 \t Time Taken: 481 sec\n",
            "[Rank 0] (epoch: 18, iters: 52, time: 0.628, data: 0.002) , D_A: 0.033, G_A: 0.579, cycle_A: 0.223, idt_A: 0.214, D_B: 0.142, G_B: 0.524, cycle_B: 0.537, idt_B: 0.083\n",
            "\n",
            "[Rank 0] (epoch: 18, iters: 152, time: 0.637, data: 0.002) , D_A: 0.068, G_A: 0.913, cycle_A: 0.256, idt_A: 0.192, D_B: 0.121, G_B: 0.386, cycle_B: 0.487, idt_B: 0.102\n",
            "\n",
            "[Rank 0] (epoch: 18, iters: 252, time: 0.630, data: 0.002) , D_A: 0.046, G_A: 0.593, cycle_A: 0.244, idt_A: 0.212, D_B: 0.165, G_B: 0.912, cycle_B: 0.630, idt_B: 0.083\n",
            "\n",
            "[Rank 0] (epoch: 18, iters: 352, time: 1.044, data: 0.003) , D_A: 0.689, G_A: 0.955, cycle_A: 0.264, idt_A: 0.362, D_B: 0.451, G_B: 0.167, cycle_B: 0.810, idt_B: 0.090\n",
            "\n",
            "[Rank 0] (epoch: 18, iters: 452, time: 0.632, data: 0.004) , D_A: 0.062, G_A: 1.530, cycle_A: 0.324, idt_A: 0.218, D_B: 0.322, G_B: 1.094, cycle_B: 0.434, idt_B: 0.118\n",
            "\n",
            "[Rank 0] (epoch: 18, iters: 552, time: 0.635, data: 0.002) , D_A: 0.031, G_A: 0.853, cycle_A: 0.232, idt_A: 0.269, D_B: 0.070, G_B: 0.868, cycle_B: 0.606, idt_B: 0.085\n",
            "\n",
            "[Rank 0] (epoch: 18, iters: 652, time: 0.636, data: 0.004) , D_A: 0.154, G_A: 0.329, cycle_A: 0.284, idt_A: 0.180, D_B: 0.197, G_B: 0.177, cycle_B: 0.481, idt_B: 0.104\n",
            "\n",
            "[Rank 0] (epoch: 18, iters: 752, time: 0.880, data: 0.002) , D_A: 0.330, G_A: 0.054, cycle_A: 0.259, idt_A: 0.223, D_B: 0.251, G_B: 1.381, cycle_B: 0.556, idt_B: 0.090\n",
            "\n",
            "[Rank 0] (epoch: 18, iters: 852, time: 0.634, data: 0.002) , D_A: 0.263, G_A: 0.357, cycle_A: 0.219, idt_A: 0.195, D_B: 0.032, G_B: 0.329, cycle_B: 0.501, idt_B: 0.082\n",
            "\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "End of epoch 18 / 200 \t Time Taken: 480 sec\n",
            "[Rank 0] (epoch: 19, iters: 8, time: 0.636, data: 0.002) , D_A: 0.196, G_A: 0.814, cycle_A: 0.199, idt_A: 0.170, D_B: 0.103, G_B: 0.386, cycle_B: 0.489, idt_B: 0.072\n",
            "\n",
            "[Rank 0] (epoch: 19, iters: 108, time: 0.631, data: 0.001) , D_A: 0.132, G_A: 0.575, cycle_A: 0.254, idt_A: 0.209, D_B: 0.037, G_B: 0.874, cycle_B: 0.489, idt_B: 0.092\n",
            "\n",
            "[Rank 0] (epoch: 19, iters: 208, time: 1.100, data: 0.002) , D_A: 0.127, G_A: 0.107, cycle_A: 0.256, idt_A: 0.186, D_B: 0.069, G_B: 1.058, cycle_B: 0.516, idt_B: 0.108\n",
            "\n",
            "[Rank 0] (epoch: 19, iters: 308, time: 0.635, data: 0.002) , D_A: 0.247, G_A: 0.215, cycle_A: 0.203, idt_A: 0.150, D_B: 0.052, G_B: 0.877, cycle_B: 0.408, idt_B: 0.078\n",
            "\n",
            "[Rank 0] (epoch: 19, iters: 408, time: 0.637, data: 0.002) , D_A: 0.246, G_A: 0.447, cycle_A: 0.164, idt_A: 0.190, D_B: 0.091, G_B: 0.426, cycle_B: 0.508, idt_B: 0.070\n",
            "\n",
            "[Rank 0] (epoch: 19, iters: 508, time: 0.633, data: 0.002) , D_A: 0.230, G_A: 1.053, cycle_A: 0.288, idt_A: 0.344, D_B: 0.074, G_B: 1.120, cycle_B: 0.915, idt_B: 0.106\n",
            "\n",
            "[Rank 0] (epoch: 19, iters: 608, time: 0.885, data: 0.002) , D_A: 0.223, G_A: 0.664, cycle_A: 0.301, idt_A: 0.182, D_B: 0.037, G_B: 0.077, cycle_B: 0.462, idt_B: 0.124\n",
            "\n",
            "[Rank 0] (epoch: 19, iters: 708, time: 0.633, data: 0.002) , D_A: 0.142, G_A: 0.568, cycle_A: 0.199, idt_A: 0.258, D_B: 0.040, G_B: 0.817, cycle_B: 0.656, idt_B: 0.072\n",
            "\n",
            "[Rank 0] (epoch: 19, iters: 808, time: 0.634, data: 0.002) , D_A: 0.149, G_A: 0.413, cycle_A: 0.221, idt_A: 0.296, D_B: 0.156, G_B: 1.446, cycle_B: 0.683, idt_B: 0.089\n",
            "\n",
            "[Rank 0] (epoch: 19, iters: 908, time: 0.632, data: 0.002) , D_A: 0.053, G_A: 0.468, cycle_A: 0.281, idt_A: 0.180, D_B: 0.024, G_B: 0.400, cycle_B: 0.457, idt_B: 0.128\n",
            "\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "End of epoch 19 / 200 \t Time Taken: 480 sec\n",
            "[Rank 0] (epoch: 20, iters: 64, time: 1.131, data: 0.002) , D_A: 0.190, G_A: 0.235, cycle_A: 0.171, idt_A: 0.184, D_B: 0.057, G_B: 0.643, cycle_B: 0.484, idt_B: 0.066\n",
            "\n",
            "[Rank 0] (epoch: 20, iters: 164, time: 0.633, data: 0.002) , D_A: 0.238, G_A: 0.307, cycle_A: 0.267, idt_A: 0.194, D_B: 0.096, G_B: 0.563, cycle_B: 0.423, idt_B: 0.106\n",
            "\n",
            "[Rank 0] (epoch: 20, iters: 264, time: 0.634, data: 0.002) , D_A: 1.651, G_A: 5.133, cycle_A: 0.381, idt_A: 0.330, D_B: 0.035, G_B: 0.825, cycle_B: 0.681, idt_B: 0.111\n",
            "\n",
            "[Rank 0] (epoch: 20, iters: 364, time: 0.631, data: 0.004) , D_A: 0.300, G_A: 0.576, cycle_A: 0.268, idt_A: 0.147, D_B: 0.059, G_B: 0.857, cycle_B: 0.381, idt_B: 0.102\n",
            "\n",
            "[Rank 0] (epoch: 20, iters: 464, time: 0.872, data: 0.002) , D_A: 0.226, G_A: 0.275, cycle_A: 0.249, idt_A: 0.179, D_B: 0.131, G_B: 1.703, cycle_B: 0.465, idt_B: 0.099\n",
            "\n",
            "[Rank 0] (epoch: 20, iters: 564, time: 0.634, data: 0.002) , D_A: 0.209, G_A: 0.243, cycle_A: 0.265, idt_A: 0.173, D_B: 0.042, G_B: 0.627, cycle_B: 0.452, idt_B: 0.106\n",
            "\n",
            "[Rank 0] (epoch: 20, iters: 664, time: 0.627, data: 0.003) , D_A: 0.281, G_A: 0.336, cycle_A: 0.191, idt_A: 0.144, D_B: 0.366, G_B: 0.096, cycle_B: 0.358, idt_B: 0.070\n",
            "\n",
            "[Rank 0] (epoch: 20, iters: 764, time: 0.634, data: 0.002) , D_A: 0.158, G_A: 0.134, cycle_A: 0.205, idt_A: 0.190, D_B: 0.052, G_B: 0.229, cycle_B: 0.434, idt_B: 0.088\n",
            "\n",
            "[Rank 0] (epoch: 20, iters: 864, time: 0.878, data: 0.002) , D_A: 0.147, G_A: 0.163, cycle_A: 0.267, idt_A: 0.235, D_B: 0.051, G_B: 1.126, cycle_B: 0.552, idt_B: 0.093\n",
            "\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "saving the model at the end of epoch 20, iters 18880\n",
            "End of epoch 20 / 200 \t Time Taken: 480 sec\n",
            "[Rank 0] (epoch: 21, iters: 20, time: 0.633, data: 0.002) , D_A: 0.210, G_A: 0.265, cycle_A: 0.210, idt_A: 0.209, D_B: 0.030, G_B: 0.637, cycle_B: 0.511, idt_B: 0.086\n",
            "\n",
            "[Rank 0] (epoch: 21, iters: 120, time: 0.634, data: 0.002) , D_A: 0.328, G_A: 0.435, cycle_A: 0.204, idt_A: 0.227, D_B: 0.123, G_B: 0.323, cycle_B: 0.509, idt_B: 0.082\n",
            "\n",
            "[Rank 0] (epoch: 21, iters: 220, time: 0.631, data: 0.002) , D_A: 0.169, G_A: 0.427, cycle_A: 0.188, idt_A: 0.189, D_B: 0.028, G_B: 0.805, cycle_B: 0.467, idt_B: 0.076\n",
            "\n",
            "[Rank 0] (epoch: 21, iters: 320, time: 1.144, data: 0.002) , D_A: 0.229, G_A: 0.506, cycle_A: 0.226, idt_A: 0.164, D_B: 0.091, G_B: 0.616, cycle_B: 0.444, idt_B: 0.095\n",
            "\n",
            "[Rank 0] (epoch: 21, iters: 420, time: 0.632, data: 0.002) , D_A: 0.224, G_A: 0.611, cycle_A: 0.296, idt_A: 0.258, D_B: 0.080, G_B: 0.520, cycle_B: 0.562, idt_B: 0.105\n",
            "\n",
            "[Rank 0] (epoch: 21, iters: 520, time: 0.633, data: 0.002) , D_A: 0.035, G_A: 0.636, cycle_A: 0.257, idt_A: 0.343, D_B: 0.089, G_B: 0.624, cycle_B: 0.650, idt_B: 0.092\n",
            "\n",
            "[Rank 0] (epoch: 21, iters: 620, time: 0.634, data: 0.002) , D_A: 0.023, G_A: 0.956, cycle_A: 0.294, idt_A: 0.210, D_B: 0.104, G_B: 0.725, cycle_B: 0.505, idt_B: 0.101\n",
            "\n",
            "[Rank 0] (epoch: 21, iters: 720, time: 0.874, data: 0.002) , D_A: 0.020, G_A: 0.694, cycle_A: 0.231, idt_A: 0.137, D_B: 0.044, G_B: 0.941, cycle_B: 0.343, idt_B: 0.069\n",
            "\n",
            "[Rank 0] (epoch: 21, iters: 820, time: 0.636, data: 0.002) , D_A: 0.014, G_A: 0.865, cycle_A: 0.294, idt_A: 0.207, D_B: 0.050, G_B: 0.863, cycle_B: 0.491, idt_B: 0.110\n",
            "\n",
            "[Rank 0] (epoch: 21, iters: 920, time: 0.632, data: 0.002) , D_A: 0.035, G_A: 0.921, cycle_A: 0.295, idt_A: 0.134, D_B: 0.689, G_B: 1.492, cycle_B: 0.344, idt_B: 0.104\n",
            "\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "End of epoch 21 / 200 \t Time Taken: 480 sec\n",
            "[Rank 0] (epoch: 22, iters: 76, time: 0.637, data: 0.004) , D_A: 0.011, G_A: 0.617, cycle_A: 0.269, idt_A: 0.155, D_B: 0.099, G_B: 0.538, cycle_B: 0.396, idt_B: 0.090\n",
            "\n",
            "[Rank 0] (epoch: 22, iters: 176, time: 1.125, data: 0.002) , D_A: 0.030, G_A: 0.817, cycle_A: 0.215, idt_A: 0.239, D_B: 0.064, G_B: 1.043, cycle_B: 0.460, idt_B: 0.075\n",
            "\n",
            "saving the latest model (epoch 22, total_iters 20000)\n",
            "[Rank 0] (epoch: 22, iters: 276, time: 0.632, data: 0.002) , D_A: 0.053, G_A: 0.536, cycle_A: 0.266, idt_A: 1.005, D_B: 0.026, G_B: 1.096, cycle_B: 0.499, idt_B: 0.097\n",
            "\n",
            "[Rank 0] (epoch: 22, iters: 376, time: 0.629, data: 0.004) , D_A: 0.041, G_A: 0.603, cycle_A: 0.214, idt_A: 0.124, D_B: 0.036, G_B: 0.704, cycle_B: 0.354, idt_B: 0.071\n",
            "\n",
            "[Rank 0] (epoch: 22, iters: 476, time: 0.637, data: 0.002) , D_A: 0.046, G_A: 0.897, cycle_A: 0.219, idt_A: 0.147, D_B: 0.083, G_B: 1.413, cycle_B: 0.398, idt_B: 0.107\n",
            "\n",
            "[Rank 0] (epoch: 22, iters: 576, time: 0.872, data: 0.002) , D_A: 0.050, G_A: 0.403, cycle_A: 0.319, idt_A: 0.175, D_B: 0.126, G_B: 0.886, cycle_B: 0.446, idt_B: 0.110\n",
            "\n",
            "[Rank 0] (epoch: 22, iters: 676, time: 0.633, data: 0.002) , D_A: 0.095, G_A: 0.190, cycle_A: 0.240, idt_A: 0.183, D_B: 0.020, G_B: 1.178, cycle_B: 0.482, idt_B: 0.081\n",
            "\n",
            "[Rank 0] (epoch: 22, iters: 776, time: 0.632, data: 0.002) , D_A: 0.171, G_A: 0.408, cycle_A: 0.305, idt_A: 0.195, D_B: 0.031, G_B: 0.811, cycle_B: 0.495, idt_B: 0.114\n",
            "\n",
            "[Rank 0] (epoch: 22, iters: 876, time: 0.633, data: 0.004) , D_A: 0.088, G_A: 0.079, cycle_A: 0.196, idt_A: 0.175, D_B: 0.097, G_B: 0.570, cycle_B: 0.486, idt_B: 0.070\n",
            "\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "End of epoch 22 / 200 \t Time Taken: 480 sec\n",
            "[Rank 0] (epoch: 23, iters: 32, time: 1.136, data: 0.004) , D_A: 0.597, G_A: 0.762, cycle_A: 0.264, idt_A: 0.210, D_B: 0.028, G_B: 0.583, cycle_B: 0.490, idt_B: 0.095\n",
            "\n",
            "[Rank 0] (epoch: 23, iters: 132, time: 0.630, data: 0.002) , D_A: 0.557, G_A: 0.040, cycle_A: 0.277, idt_A: 0.194, D_B: 0.086, G_B: 0.324, cycle_B: 0.540, idt_B: 0.088\n",
            "\n",
            "[Rank 0] (epoch: 23, iters: 232, time: 0.632, data: 0.004) , D_A: 0.227, G_A: 0.271, cycle_A: 0.150, idt_A: 0.124, D_B: 0.055, G_B: 1.211, cycle_B: 0.304, idt_B: 0.056\n",
            "\n",
            "[Rank 0] (epoch: 23, iters: 332, time: 0.630, data: 0.002) , D_A: 0.115, G_A: 0.350, cycle_A: 0.212, idt_A: 0.176, D_B: 0.147, G_B: 0.289, cycle_B: 0.447, idt_B: 0.080\n",
            "\n",
            "[Rank 0] (epoch: 23, iters: 432, time: 0.917, data: 0.002) , D_A: 0.443, G_A: 0.098, cycle_A: 0.234, idt_A: 0.186, D_B: 0.148, G_B: 0.498, cycle_B: 0.497, idt_B: 0.065\n",
            "\n",
            "[Rank 0] (epoch: 23, iters: 532, time: 0.634, data: 0.002) , D_A: 0.227, G_A: 0.145, cycle_A: 0.187, idt_A: 0.166, D_B: 0.073, G_B: 0.558, cycle_B: 0.422, idt_B: 0.064\n",
            "\n",
            "[Rank 0] (epoch: 23, iters: 632, time: 0.631, data: 0.002) , D_A: 0.112, G_A: 0.517, cycle_A: 0.258, idt_A: 0.171, D_B: 0.023, G_B: 0.739, cycle_B: 0.475, idt_B: 0.097\n",
            "\n",
            "[Rank 0] (epoch: 23, iters: 732, time: 0.634, data: 0.004) , D_A: 0.256, G_A: 0.718, cycle_A: 0.241, idt_A: 0.141, D_B: 0.017, G_B: 1.154, cycle_B: 0.380, idt_B: 0.086\n",
            "\n",
            "[Rank 0] (epoch: 23, iters: 832, time: 0.862, data: 0.003) , D_A: 0.451, G_A: 0.638, cycle_A: 0.228, idt_A: 0.136, D_B: 0.095, G_B: 1.594, cycle_B: 0.322, idt_B: 0.074\n",
            "\n",
            "[Rank 0] (epoch: 23, iters: 932, time: 0.635, data: 0.002) , D_A: 0.225, G_A: 0.503, cycle_A: 0.298, idt_A: 0.131, D_B: 0.121, G_B: 1.014, cycle_B: 0.351, idt_B: 0.113\n",
            "\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "End of epoch 23 / 200 \t Time Taken: 480 sec\n",
            "[Rank 0] (epoch: 24, iters: 88, time: 0.631, data: 0.004) , D_A: 0.250, G_A: 0.488, cycle_A: 0.277, idt_A: 0.118, D_B: 0.053, G_B: 0.533, cycle_B: 0.342, idt_B: 0.108\n",
            "\n",
            "[Rank 0] (epoch: 24, iters: 188, time: 0.633, data: 0.002) , D_A: 0.137, G_A: 0.883, cycle_A: 0.217, idt_A: 0.193, D_B: 0.032, G_B: 0.666, cycle_B: 0.506, idt_B: 0.063\n",
            "\n",
            "[Rank 0] (epoch: 24, iters: 288, time: 1.150, data: 0.002) , D_A: 0.089, G_A: 0.279, cycle_A: 0.210, idt_A: 0.154, D_B: 0.018, G_B: 1.196, cycle_B: 0.420, idt_B: 0.077\n",
            "\n",
            "[Rank 0] (epoch: 24, iters: 388, time: 0.638, data: 0.002) , D_A: 0.124, G_A: 0.300, cycle_A: 0.229, idt_A: 0.328, D_B: 0.072, G_B: 0.567, cycle_B: 0.617, idt_B: 0.077\n",
            "\n",
            "[Rank 0] (epoch: 24, iters: 488, time: 0.633, data: 0.002) , D_A: 0.236, G_A: 0.182, cycle_A: 0.284, idt_A: 0.156, D_B: 0.030, G_B: 0.915, cycle_B: 0.410, idt_B: 0.105\n",
            "\n",
            "[Rank 0] (epoch: 24, iters: 588, time: 0.631, data: 0.002) , D_A: 0.165, G_A: 0.541, cycle_A: 0.197, idt_A: 0.175, D_B: 0.047, G_B: 0.993, cycle_B: 0.433, idt_B: 0.075\n",
            "\n",
            "[Rank 0] (epoch: 24, iters: 688, time: 0.869, data: 0.002) , D_A: 0.125, G_A: 0.219, cycle_A: 0.221, idt_A: 0.128, D_B: 0.026, G_B: 0.924, cycle_B: 0.402, idt_B: 0.088\n",
            "\n",
            "[Rank 0] (epoch: 24, iters: 788, time: 0.634, data: 0.002) , D_A: 0.128, G_A: 0.267, cycle_A: 0.231, idt_A: 0.175, D_B: 0.043, G_B: 0.723, cycle_B: 0.459, idt_B: 0.079\n",
            "\n",
            "[Rank 0] (epoch: 24, iters: 888, time: 0.632, data: 0.002) , D_A: 0.082, G_A: 0.443, cycle_A: 0.234, idt_A: 0.200, D_B: 0.081, G_B: 0.994, cycle_B: 0.641, idt_B: 0.080\n",
            "\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "End of epoch 24 / 200 \t Time Taken: 480 sec\n",
            "[Rank 0] (epoch: 25, iters: 44, time: 0.630, data: 0.002) , D_A: 0.169, G_A: 0.265, cycle_A: 0.258, idt_A: 0.133, D_B: 0.040, G_B: 0.651, cycle_B: 0.350, idt_B: 0.092\n",
            "\n",
            "[Rank 0] (epoch: 25, iters: 144, time: 1.125, data: 0.002) , D_A: 0.296, G_A: 0.573, cycle_A: 0.294, idt_A: 0.179, D_B: 0.054, G_B: 1.430, cycle_B: 0.466, idt_B: 0.114\n",
            "\n",
            "[Rank 0] (epoch: 25, iters: 244, time: 0.635, data: 0.002) , D_A: 0.081, G_A: 0.226, cycle_A: 0.228, idt_A: 0.184, D_B: 0.095, G_B: 1.125, cycle_B: 0.446, idt_B: 0.079\n",
            "\n",
            "[Rank 0] (epoch: 25, iters: 344, time: 0.633, data: 0.002) , D_A: 0.204, G_A: 0.444, cycle_A: 0.277, idt_A: 0.182, D_B: 0.111, G_B: 0.402, cycle_B: 0.507, idt_B: 0.102\n",
            "\n",
            "[Rank 0] (epoch: 25, iters: 444, time: 0.634, data: 0.004) , D_A: 0.145, G_A: 0.365, cycle_A: 0.209, idt_A: 0.144, D_B: 0.029, G_B: 0.546, cycle_B: 0.391, idt_B: 0.076\n",
            "\n",
            "[Rank 0] (epoch: 25, iters: 544, time: 0.872, data: 0.002) , D_A: 0.270, G_A: 0.110, cycle_A: 0.179, idt_A: 0.236, D_B: 0.031, G_B: 0.750, cycle_B: 0.564, idt_B: 0.068\n",
            "\n",
            "[Rank 0] (epoch: 25, iters: 644, time: 0.633, data: 0.002) , D_A: 0.276, G_A: 0.091, cycle_A: 0.229, idt_A: 0.113, D_B: 0.033, G_B: 0.738, cycle_B: 0.294, idt_B: 0.088\n",
            "\n",
            "[Rank 0] (epoch: 25, iters: 744, time: 0.631, data: 0.002) , D_A: 0.256, G_A: 0.573, cycle_A: 0.203, idt_A: 0.205, D_B: 0.078, G_B: 0.575, cycle_B: 0.722, idt_B: 0.075\n",
            "\n",
            "[Rank 0] (epoch: 25, iters: 844, time: 0.634, data: 0.002) , D_A: 0.175, G_A: 0.306, cycle_A: 0.298, idt_A: 0.129, D_B: 0.080, G_B: 0.994, cycle_B: 0.340, idt_B: 0.103\n",
            "\n",
            "[Rank 0] (epoch: 25, iters: 944, time: 0.920, data: 0.004) , D_A: 0.238, G_A: 0.781, cycle_A: 0.288, idt_A: 0.160, D_B: 0.025, G_B: 0.410, cycle_B: 0.415, idt_B: 0.103\n",
            "\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "saving the model at the end of epoch 25, iters 23600\n",
            "End of epoch 25 / 200 \t Time Taken: 481 sec\n",
            "[Rank 0] (epoch: 26, iters: 100, time: 0.637, data: 0.413) , D_A: 0.194, G_A: 0.228, cycle_A: 0.173, idt_A: 0.190, D_B: 0.042, G_B: 0.590, cycle_B: 0.493, idt_B: 0.065\n",
            "\n",
            "[Rank 0] (epoch: 26, iters: 200, time: 0.632, data: 0.002) , D_A: 0.061, G_A: 0.640, cycle_A: 0.198, idt_A: 0.181, D_B: 0.036, G_B: 0.955, cycle_B: 0.496, idt_B: 0.068\n",
            "\n",
            "[Rank 0] (epoch: 26, iters: 300, time: 0.631, data: 0.002) , D_A: 0.234, G_A: 0.254, cycle_A: 0.217, idt_A: 0.138, D_B: 0.186, G_B: 1.535, cycle_B: 0.343, idt_B: 0.073\n",
            "\n",
            "[Rank 0] (epoch: 26, iters: 400, time: 1.101, data: 0.005) , D_A: 0.112, G_A: 0.387, cycle_A: 0.240, idt_A: 0.248, D_B: 0.205, G_B: 0.814, cycle_B: 0.572, idt_B: 0.087\n",
            "\n",
            "[Rank 0] (epoch: 26, iters: 500, time: 0.633, data: 0.002) , D_A: 0.226, G_A: 1.941, cycle_A: 0.437, idt_A: 0.235, D_B: 0.091, G_B: 1.339, cycle_B: 0.541, idt_B: 0.204\n",
            "\n",
            "[Rank 0] (epoch: 26, iters: 600, time: 0.635, data: 0.002) , D_A: 0.039, G_A: 1.105, cycle_A: 0.430, idt_A: 0.185, D_B: 0.025, G_B: 0.405, cycle_B: 0.456, idt_B: 0.175\n",
            "\n",
            "[Rank 0] (epoch: 26, iters: 700, time: 0.634, data: 0.002) , D_A: 0.027, G_A: 1.174, cycle_A: 0.424, idt_A: 0.253, D_B: 0.012, G_B: 0.978, cycle_B: 0.968, idt_B: 0.155\n",
            "\n",
            "[Rank 0] (epoch: 26, iters: 800, time: 0.843, data: 0.002) , D_A: 0.021, G_A: 0.991, cycle_A: 0.323, idt_A: 0.293, D_B: 0.016, G_B: 1.109, cycle_B: 0.620, idt_B: 0.108\n",
            "\n",
            "[Rank 0] (epoch: 26, iters: 900, time: 0.631, data: 0.002) , D_A: 0.026, G_A: 0.826, cycle_A: 0.289, idt_A: 0.363, D_B: 0.008, G_B: 0.818, cycle_B: 0.819, idt_B: 0.102\n",
            "\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "End of epoch 26 / 200 \t Time Taken: 479 sec\n",
            "[Rank 0] (epoch: 27, iters: 56, time: 0.633, data: 0.002) , D_A: 0.018, G_A: 1.137, cycle_A: 0.318, idt_A: 0.164, D_B: 0.031, G_B: 0.757, cycle_B: 0.452, idt_B: 0.115\n",
            "\n",
            "[Rank 0] (epoch: 27, iters: 156, time: 0.633, data: 0.002) , D_A: 0.014, G_A: 0.788, cycle_A: 0.286, idt_A: 0.118, D_B: 0.008, G_B: 0.638, cycle_B: 0.330, idt_B: 0.103\n",
            "\n",
            "[Rank 0] (epoch: 27, iters: 256, time: 1.217, data: 0.002) , D_A: 0.015, G_A: 0.678, cycle_A: 0.328, idt_A: 0.170, D_B: 0.005, G_B: 1.019, cycle_B: 0.649, idt_B: 0.112\n",
            "\n",
            "[Rank 0] (epoch: 27, iters: 356, time: 0.632, data: 0.002) , D_A: 0.015, G_A: 0.785, cycle_A: 0.253, idt_A: 0.150, D_B: 0.022, G_B: 1.065, cycle_B: 0.419, idt_B: 0.089\n",
            "\n",
            "[Rank 0] (epoch: 27, iters: 456, time: 0.632, data: 0.002) , D_A: 0.060, G_A: 0.550, cycle_A: 0.307, idt_A: 0.125, D_B: 0.010, G_B: 0.568, cycle_B: 0.338, idt_B: 0.113\n",
            "\n",
            "saving the latest model (epoch 27, total_iters 25000)\n",
            "[Rank 0] (epoch: 27, iters: 556, time: 0.632, data: 0.002) , D_A: 0.015, G_A: 0.829, cycle_A: 0.276, idt_A: 0.173, D_B: 0.016, G_B: 0.886, cycle_B: 0.445, idt_B: 0.095\n",
            "\n",
            "[Rank 0] (epoch: 27, iters: 656, time: 0.851, data: 0.003) , D_A: 0.054, G_A: 0.511, cycle_A: 0.307, idt_A: 0.180, D_B: 0.015, G_B: 1.077, cycle_B: 0.455, idt_B: 0.121\n",
            "\n",
            "[Rank 0] (epoch: 27, iters: 756, time: 0.635, data: 0.002) , D_A: 0.068, G_A: 0.733, cycle_A: 0.279, idt_A: 0.203, D_B: 0.009, G_B: 0.911, cycle_B: 0.494, idt_B: 0.102\n",
            "\n",
            "[Rank 0] (epoch: 27, iters: 856, time: 0.631, data: 0.004) , D_A: 0.068, G_A: 0.452, cycle_A: 0.212, idt_A: 0.121, D_B: 0.053, G_B: 0.942, cycle_B: 0.354, idt_B: 0.072\n",
            "\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "End of epoch 27 / 200 \t Time Taken: 479 sec\n",
            "[Rank 0] (epoch: 28, iters: 12, time: 0.634, data: 0.004) , D_A: 0.078, G_A: 0.142, cycle_A: 0.242, idt_A: 0.190, D_B: 0.008, G_B: 0.668, cycle_B: 0.482, idt_B: 0.089\n",
            "\n",
            "[Rank 0] (epoch: 28, iters: 112, time: 1.127, data: 0.002) , D_A: 0.159, G_A: 0.310, cycle_A: 0.282, idt_A: 0.171, D_B: 0.007, G_B: 0.581, cycle_B: 0.427, idt_B: 0.111\n",
            "\n",
            "[Rank 0] (epoch: 28, iters: 212, time: 0.634, data: 0.002) , D_A: 0.184, G_A: 0.570, cycle_A: 0.255, idt_A: 0.177, D_B: 0.007, G_B: 0.751, cycle_B: 0.519, idt_B: 0.089\n",
            "\n",
            "[Rank 0] (epoch: 28, iters: 312, time: 0.633, data: 0.002) , D_A: 0.332, G_A: 0.424, cycle_A: 0.175, idt_A: 0.226, D_B: 0.027, G_B: 1.195, cycle_B: 0.645, idt_B: 0.068\n",
            "\n",
            "[Rank 0] (epoch: 28, iters: 412, time: 0.634, data: 0.002) , D_A: 0.097, G_A: 0.436, cycle_A: 0.213, idt_A: 0.163, D_B: 0.033, G_B: 0.564, cycle_B: 0.494, idt_B: 0.084\n",
            "\n",
            "[Rank 0] (epoch: 28, iters: 512, time: 1.259, data: 0.002) , D_A: 0.133, G_A: 0.927, cycle_A: 0.238, idt_A: 0.146, D_B: 0.037, G_B: 0.816, cycle_B: 0.397, idt_B: 0.087\n",
            "\n",
            "[Rank 0] (epoch: 28, iters: 612, time: 0.634, data: 0.004) , D_A: 0.080, G_A: 0.308, cycle_A: 0.211, idt_A: 0.177, D_B: 0.037, G_B: 0.678, cycle_B: 0.489, idt_B: 0.079\n",
            "\n",
            "[Rank 0] (epoch: 28, iters: 712, time: 0.635, data: 0.002) , D_A: 0.088, G_A: 0.195, cycle_A: 0.246, idt_A: 0.158, D_B: 0.036, G_B: 0.917, cycle_B: 0.477, idt_B: 0.092\n",
            "\n",
            "[Rank 0] (epoch: 28, iters: 812, time: 0.634, data: 0.003) , D_A: 0.171, G_A: 0.273, cycle_A: 0.189, idt_A: 0.147, D_B: 0.019, G_B: 0.509, cycle_B: 0.437, idt_B: 0.076\n",
            "\n",
            "[Rank 0] (epoch: 28, iters: 912, time: 0.889, data: 0.002) , D_A: 0.162, G_A: 0.691, cycle_A: 0.243, idt_A: 0.213, D_B: 0.025, G_B: 0.772, cycle_B: 0.486, idt_B: 0.085\n",
            "\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "End of epoch 28 / 200 \t Time Taken: 481 sec\n",
            "[Rank 0] (epoch: 29, iters: 68, time: 0.632, data: 0.002) , D_A: 0.139, G_A: 0.419, cycle_A: 0.248, idt_A: 0.115, D_B: 0.024, G_B: 0.992, cycle_B: 0.348, idt_B: 0.092\n",
            "\n",
            "[Rank 0] (epoch: 29, iters: 168, time: 0.633, data: 0.002) , D_A: 0.258, G_A: 1.408, cycle_A: 1.384, idt_A: 0.271, D_B: 0.106, G_B: 0.462, cycle_B: 0.676, idt_B: 0.396\n",
            "\n",
            "[Rank 0] (epoch: 29, iters: 268, time: 0.633, data: 0.002) , D_A: 0.289, G_A: 0.816, cycle_A: 0.203, idt_A: 0.245, D_B: 0.088, G_B: 0.952, cycle_B: 0.520, idt_B: 0.078\n",
            "\n",
            "[Rank 0] (epoch: 29, iters: 368, time: 1.093, data: 0.002) , D_A: 0.081, G_A: 1.318, cycle_A: 0.259, idt_A: 0.124, D_B: 0.033, G_B: 0.765, cycle_B: 0.344, idt_B: 0.094\n",
            "\n",
            "[Rank 0] (epoch: 29, iters: 468, time: 0.632, data: 0.004) , D_A: 0.026, G_A: 0.908, cycle_A: 0.247, idt_A: 0.130, D_B: 0.133, G_B: 0.545, cycle_B: 0.336, idt_B: 0.084\n",
            "\n",
            "[Rank 0] (epoch: 29, iters: 568, time: 0.634, data: 0.002) , D_A: 0.071, G_A: 0.930, cycle_A: 0.298, idt_A: 0.195, D_B: 0.061, G_B: 0.554, cycle_B: 0.483, idt_B: 0.107\n",
            "\n",
            "[Rank 0] (epoch: 29, iters: 668, time: 0.634, data: 0.002) , D_A: 0.085, G_A: 0.391, cycle_A: 0.275, idt_A: 0.158, D_B: 0.084, G_B: 0.813, cycle_B: 0.422, idt_B: 0.108\n",
            "\n",
            "[Rank 0] (epoch: 29, iters: 768, time: 0.942, data: 0.002) , D_A: 0.081, G_A: 0.402, cycle_A: 0.173, idt_A: 0.157, D_B: 0.030, G_B: 0.527, cycle_B: 0.408, idt_B: 0.064\n",
            "\n",
            "[Rank 0] (epoch: 29, iters: 868, time: 0.636, data: 0.002) , D_A: 0.036, G_A: 0.266, cycle_A: 0.255, idt_A: 0.174, D_B: 0.025, G_B: 1.082, cycle_B: 0.493, idt_B: 0.085\n",
            "\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "End of epoch 29 / 200 \t Time Taken: 479 sec\n",
            "[Rank 0] (epoch: 30, iters: 24, time: 0.634, data: 0.002) , D_A: 0.059, G_A: 0.806, cycle_A: 0.265, idt_A: 0.158, D_B: 0.039, G_B: 0.695, cycle_B: 0.430, idt_B: 0.092\n",
            "\n",
            "[Rank 0] (epoch: 30, iters: 124, time: 0.631, data: 0.002) , D_A: 0.128, G_A: 0.252, cycle_A: 0.305, idt_A: 0.134, D_B: 0.040, G_B: 0.884, cycle_B: 0.386, idt_B: 0.102\n",
            "\n",
            "[Rank 0] (epoch: 30, iters: 224, time: 1.134, data: 0.002) , D_A: 0.025, G_A: 0.412, cycle_A: 0.223, idt_A: 0.159, D_B: 0.222, G_B: 1.440, cycle_B: 0.459, idt_B: 0.089\n",
            "\n",
            "[Rank 0] (epoch: 30, iters: 324, time: 0.634, data: 0.002) , D_A: 0.174, G_A: 0.222, cycle_A: 0.217, idt_A: 0.271, D_B: 0.025, G_B: 0.760, cycle_B: 0.621, idt_B: 0.086\n",
            "\n",
            "[Rank 0] (epoch: 30, iters: 424, time: 0.634, data: 0.002) , D_A: 0.073, G_A: 0.224, cycle_A: 0.210, idt_A: 0.218, D_B: 0.044, G_B: 0.621, cycle_B: 0.500, idt_B: 0.087\n",
            "\n",
            "[Rank 0] (epoch: 30, iters: 524, time: 0.632, data: 0.003) , D_A: 0.050, G_A: 0.992, cycle_A: 0.348, idt_A: 0.235, D_B: 0.023, G_B: 0.881, cycle_B: 0.582, idt_B: 0.137\n",
            "\n",
            "[Rank 0] (epoch: 30, iters: 624, time: 1.095, data: 0.002) , D_A: 0.110, G_A: 1.099, cycle_A: 0.216, idt_A: 0.173, D_B: 0.049, G_B: 1.132, cycle_B: 0.422, idt_B: 0.093\n",
            "\n",
            "[Rank 0] (epoch: 30, iters: 724, time: 0.635, data: 0.002) , D_A: 0.336, G_A: 0.795, cycle_A: 0.245, idt_A: 0.174, D_B: 0.019, G_B: 0.823, cycle_B: 0.433, idt_B: 0.091\n",
            "\n",
            "[Rank 0] (epoch: 30, iters: 824, time: 0.636, data: 0.002) , D_A: 0.135, G_A: 0.286, cycle_A: 0.264, idt_A: 0.160, D_B: 0.010, G_B: 1.059, cycle_B: 0.432, idt_B: 0.096\n",
            "\n",
            "[Rank 0] (epoch: 30, iters: 924, time: 0.634, data: 0.002) , D_A: 0.162, G_A: 0.246, cycle_A: 0.224, idt_A: 0.235, D_B: 0.006, G_B: 0.945, cycle_B: 0.548, idt_B: 0.084\n",
            "\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "saving the model at the end of epoch 30, iters 28320\n",
            "End of epoch 30 / 200 \t Time Taken: 481 sec\n",
            "[Rank 0] (epoch: 31, iters: 80, time: 1.285, data: 0.002) , D_A: 0.127, G_A: 0.423, cycle_A: 0.269, idt_A: 0.148, D_B: 0.007, G_B: 0.839, cycle_B: 0.391, idt_B: 0.095\n",
            "\n",
            "[Rank 0] (epoch: 31, iters: 180, time: 0.636, data: 0.003) , D_A: 0.039, G_A: 0.313, cycle_A: 0.190, idt_A: 0.227, D_B: 0.009, G_B: 0.967, cycle_B: 0.578, idt_B: 0.075\n",
            "\n",
            "[Rank 0] (epoch: 31, iters: 280, time: 0.632, data: 0.002) , D_A: 0.044, G_A: 0.399, cycle_A: 0.239, idt_A: 0.140, D_B: 0.005, G_B: 0.846, cycle_B: 0.383, idt_B: 0.056\n",
            "\n",
            "[Rank 0] (epoch: 31, iters: 380, time: 0.633, data: 0.002) , D_A: 0.228, G_A: 0.561, cycle_A: 0.270, idt_A: 0.146, D_B: 0.007, G_B: 1.016, cycle_B: 0.391, idt_B: 0.100\n",
            "\n",
            "[Rank 0] (epoch: 31, iters: 480, time: 0.860, data: 0.002) , D_A: 0.234, G_A: 0.654, cycle_A: 0.198, idt_A: 0.162, D_B: 0.008, G_B: 0.887, cycle_B: 0.433, idt_B: 0.076\n",
            "\n",
            "[Rank 0] (epoch: 31, iters: 580, time: 0.635, data: 0.002) , D_A: 0.034, G_A: 0.225, cycle_A: 0.201, idt_A: 0.182, D_B: 0.008, G_B: 1.028, cycle_B: 0.424, idt_B: 0.071\n",
            "\n",
            "[Rank 0] (epoch: 31, iters: 680, time: 0.634, data: 0.002) , D_A: 0.123, G_A: 0.494, cycle_A: 0.208, idt_A: 0.163, D_B: 0.008, G_B: 0.859, cycle_B: 0.409, idt_B: 0.078\n",
            "\n",
            "[Rank 0] (epoch: 31, iters: 780, time: 0.634, data: 0.003) , D_A: 0.076, G_A: 0.253, cycle_A: 0.298, idt_A: 0.438, D_B: 0.019, G_B: 0.756, cycle_B: 0.915, idt_B: 0.106\n",
            "\n",
            "[Rank 0] (epoch: 31, iters: 880, time: 0.860, data: 0.002) , D_A: 0.093, G_A: 0.347, cycle_A: 0.154, idt_A: 0.160, D_B: 0.011, G_B: 1.144, cycle_B: 0.439, idt_B: 0.056\n",
            "\n",
            "learning rate 0.0002000 -> 0.0002000\n",
            "End of epoch 31 / 200 \t Time Taken: 481 sec\n",
            "[Rank 0] (epoch: 32, iters: 36, time: 0.633, data: 0.002) , D_A: 0.155, G_A: 0.274, cycle_A: 0.275, idt_A: 0.227, D_B: 0.007, G_B: 0.914, cycle_B: 0.586, idt_B: 0.106\n",
            "\n",
            "[Rank 0] (epoch: 32, iters: 136, time: 0.633, data: 0.002) , D_A: 0.014, G_A: 1.042, cycle_A: 0.338, idt_A: 0.179, D_B: 0.017, G_B: 1.159, cycle_B: 0.514, idt_B: 0.123\n",
            "\n",
            "[Rank 0] (epoch: 32, iters: 236, time: 0.635, data: 0.002) , D_A: 0.009, G_A: 0.970, cycle_A: 0.300, idt_A: 0.164, D_B: 0.012, G_B: 1.154, cycle_B: 0.407, idt_B: 0.107\n",
            "\n",
            "[Rank 0] (epoch: 32, iters: 336, time: 1.226, data: 0.002) , D_A: 0.017, G_A: 0.851, cycle_A: 0.339, idt_A: 0.183, D_B: 0.015, G_B: 1.138, cycle_B: 0.455, idt_B: 0.113\n",
            "\n",
            "[Rank 0] (epoch: 32, iters: 436, time: 0.635, data: 0.002) , D_A: 0.024, G_A: 0.712, cycle_A: 0.197, idt_A: 0.174, D_B: 0.008, G_B: 0.974, cycle_B: 0.442, idt_B: 0.062\n",
            "\n",
            "[Rank 0] (epoch: 32, iters: 536, time: 0.634, data: 0.002) , D_A: 0.010, G_A: 0.786, cycle_A: 0.240, idt_A: 0.157, D_B: 0.022, G_B: 1.123, cycle_B: 0.454, idt_B: 0.083\n",
            "\n",
            "[Rank 0] (epoch: 32, iters: 636, time: 0.634, data: 0.002) , D_A: 0.014, G_A: 1.033, cycle_A: 0.302, idt_A: 0.114, D_B: 0.011, G_B: 0.967, cycle_B: 0.336, idt_B: 0.101\n",
            "\n",
            "[Rank 0] (epoch: 32, iters: 736, time: 1.076, data: 0.002) , D_A: 0.007, G_A: 0.860, cycle_A: 0.203, idt_A: 0.176, D_B: 0.005, G_B: 0.946, cycle_B: 0.470, idt_B: 0.073\n",
            "\n",
            "saving the latest model (epoch 32, total_iters 30000)\n"
          ]
        }
      ],
      "source": [
        "# !python train.py --dataroot ./datasets/chess_data --name chess_cut --model cut --CUT_mode cut\n",
        "# !python train.py --dataroot ./datasets/grumpifycat --name grumpycat_FastCUT --CUT_mode FastCUT\n",
        "# !python -m visdom.server\n",
        "\n",
        "!python train.py --dataroot ./datasets/chess_data --name chess_data_cyclegan --model cycle_gan --use_wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4hdUx1AF-Enr"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ps1es_6ILU5l",
        "outputId": "75538fd6-34ba-4cd9-aa76-696d8634ee28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cp: cannot stat '/content/checkpoints': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!cp -r /content/checkpoints \"/content/drive/My Drive/ChessProject/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1C3Xvh5cC-7n"
      },
      "source": [
        "## Inference (Testing)\n",
        "Once training is complete, run this cell to translate your test renders into realistic images.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZ19OEvkC-7n",
        "outputId": "fefd1213-5c94-4a94-b3a1-817cc322facc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "python3: can't open file '/content/test.py': [Errno 2] No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!python test.py --dataroot ./datasets/chess_data --name chess_data_cyclegan --model cycle_gan"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
